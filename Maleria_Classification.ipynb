{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9694891-ed5d-43e8-b003-4f6a4f788f6c",
   "metadata": {},
   "source": [
    "# <font color=Red> Aim of the Project\n",
    "### In this project, we will classify malaria cell images as either infected or uninfected.  \n",
    "A deep learning model for image classification will be developed and deployed using Hugging Face.\n",
    "https://huggingface.co/spaces/HarunDemircioglu11/Malaria_Cell_Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce5252-6e72-45da-b93d-247459f07e4e",
   "metadata": {},
   "source": [
    "<img src='https://img.freepik.com/fotos-premium/mosquitos-aedes-aedes-transmitem-doencas-dia-mundial-da-malaria-25-de-abril_10221-19519.jpg?w=996'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ae4b814-e8bd-4868-a3b0-1a4d8f250061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #OpenCV kut. goruntuleri okuma yazma duzenleme ve analiz etme\n",
    "import pandas as pd #\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84cdf6ca-a241-410a-884a-fcadcb8b41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mevcut çalışma dizini: C:\\Users\\harunn\\Music\\ARTIFICIAL INTELLIGENCE\\MALERIA\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "current_path = Path.cwd()\n",
    "\n",
    "# Çalışma dizinini yazdır\n",
    "print(f\"Mevcut çalışma dizini: {current_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c7ab8-b081-4fa6-b02b-dbe77821861d",
   "metadata": {},
   "source": [
    "- This line defines the two possible classes for your image classification task: 'Parasitized' (cells infected with parasites) and 'Uninfected' (healthy cells).\n",
    "\n",
    "- This line specifies the directory path where the cell images used for training and testing are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30e6c076-5fdc-4405-b71e-579abcf21e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['Parasitized','Uninfected']\n",
    "img_path='cell_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52c01e-de53-40d6-800e-ea62c9aff679",
   "metadata": {},
   "source": [
    "- An empty list called `img_list` is created to store the file paths of all images that will be read from the folders.\n",
    "- Another empty list called `label_list` is created to store the corresponding label (class) for each image.\n",
    "- The outer loop iterates through each class label (e.g., 'Parasitized' and 'Uninfected').\n",
    "- For each label, the inner loop visits the respective folder and iterates through all image files in that folder.\n",
    "- The full file path of each image is added to `img_list`.\n",
    "- The corresponding class label is added to `label_list`, ensuring that each image is matched with its correct label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d1246-2436-49a1-a896-65d02799d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list=[] # ici bos listem resimleri okuyacagim sonr okudugum resimleri listemin icine atacagim\n",
    "label_list=[] # okudugum resmin karsisina etiketimi koyacagim \n",
    "for label in labels: # kansere ya da kanser olmyanlarin klasorune git dedim once klasordeki her bir resmi ziyaret edip her birinin ismini alacagim\n",
    "    for img_file in os.listdir(img_path+label): #labeli alinca onun altindaki kanser ve non kansere gittim\n",
    "        img_list.append(img_path+label+'/'+img_file)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793e767-8b93-4db2-b474-cfd8affa6246",
   "metadata": {},
   "source": [
    "- The code first imports the required libraries: `Path` from `pathlib` for easier path operations and `os` for directory scanning.\n",
    "- Two class labels, 'Parasitized' and 'Uninfected', are defined, and the main image directory is set using `Path`.\n",
    "- Two empty lists, `img_list` and `label_list`, are created to store the image file paths and their corresponding labels.\n",
    "- For each class label, the code constructs the path to the relevant folder (e.g., `cell_images/Parasitized`).\n",
    "- It checks if the folder exists. If not, it prints a warning message.\n",
    "- If the folder exists, it uses `os.scandir()` to efficiently scan all files within the folder.\n",
    "- For each file:\n",
    "    - The loop is limited to the first 500 images per class to avoid loading too many files.\n",
    "    - It checks if the file is a regular image file with the extension .jpg, .jpeg, or .png.\n",
    "    - Files named \"thumbs.db\" are skipped, as they are not image data.\n",
    "    - The file path is appended to `img_list`, and its label is appended to `label_list`.\n",
    "- At the end, the code prints the total number of loaded images.\n",
    "- The comment indicates that this code was originally provided by Çağla Derin Sahin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f6f22da-e7c0-4697-a6d6-5eace40351be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 görüntü yüklendi.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "labels = ['Parasitized', 'Uninfected']\n",
    "img_path = Path('cell_images')\n",
    "\n",
    "img_list = []\n",
    "label_list = []\n",
    "\n",
    "for label in labels:\n",
    "    folder_path = img_path / label\n",
    "    if folder_path.exists():\n",
    "        with os.scandir(folder_path) as files:\n",
    "            for i, file in enumerate(files):\n",
    "                if i >= 500:  # \n",
    "                    break\n",
    "                if file.is_file() and file.name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    if \"thumbs.db\" in file.name.lower():\n",
    "                        continue\n",
    "                    img_list.append(str(file.path))\n",
    "                    label_list.append(label)\n",
    "    else:\n",
    "        print(f\"{folder_path} bulunamadı!\")\n",
    "\n",
    "print(f\"{len(img_list)} görüntü yüklendi.\")\n",
    "## Bu kod Cagla inandan alinmistir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc91d9-3a5e-4817-96e9-89376fdd23ab",
   "metadata": {},
   "source": [
    "- This line creates a DataFrame named `df` with two columns:  \n",
    "  - `'img'`: contains the file paths of all images,  \n",
    "  - `'label'`: contains the corresponding class label (e.g., 'Parasitized' or 'Uninfected') for each image.  \n",
    "- This DataFrame organizes the image data and labels in a structured table, making it easier to use for further data processing or model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b95eb92-7bfd-4b0a-928f-b484a185d61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parasitized', 'Uninfected']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('cell_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adf8f94e-6fb5-416b-9f78-93de609c771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'img':img_list,'label':label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a8f95cf-d4d4-4ee9-aa28-0155e3f12728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cell_images\\Parasitized\\C100P61ThinF_IMG_20150...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cell_images\\Parasitized\\C100P61ThinF_IMG_20150...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cell_images\\Parasitized\\C100P61ThinF_IMG_20150...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cell_images\\Parasitized\\C100P61ThinF_IMG_20150...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cell_images\\Parasitized\\C100P61ThinF_IMG_20150...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img        label\n",
       "0  cell_images\\Parasitized\\C100P61ThinF_IMG_20150...  Parasitized\n",
       "1  cell_images\\Parasitized\\C100P61ThinF_IMG_20150...  Parasitized\n",
       "2  cell_images\\Parasitized\\C100P61ThinF_IMG_20150...  Parasitized\n",
       "3  cell_images\\Parasitized\\C100P61ThinF_IMG_20150...  Parasitized\n",
       "4  cell_images\\Parasitized\\C100P61ThinF_IMG_20150...  Parasitized"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2f025-7b40-4bf4-82c7-4fd1ec335316",
   "metadata": {},
   "source": [
    "- This line creates a dictionary named `d` that maps each class label to a numerical value:\n",
    "  - `'Parasitized'` is mapped to `1` (representing infected),\n",
    "  - `'Uninfected'` is mapped to `0` (representing healthy).\n",
    "- This mapping is typically used to convert categorical class labels into numerical labels for machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8ffeb7a-67e3-41da-ae5a-90f103b4562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd10b50-8b0f-4f6f-98f4-8fcc723d7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'Parasitized':1, 'Uninfected':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec50e530-8878-4773-bac7-db4dd81c9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encode_label']=df['label'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d9f7fa7-60fc-4e96-8a17-c8b8076d9e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>encode_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>cell_images\\Uninfected\\C107P68ThinF_IMG_201509...</td>\n",
       "      <td>Uninfected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>cell_images\\Uninfected\\C107P68ThinF_IMG_201509...</td>\n",
       "      <td>Uninfected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>cell_images\\Uninfected\\C107P68ThinF_IMG_201509...</td>\n",
       "      <td>Uninfected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>cell_images\\Uninfected\\C107P68ThinF_IMG_201509...</td>\n",
       "      <td>Uninfected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>cell_images\\Uninfected\\C107P68ThinF_IMG_201509...</td>\n",
       "      <td>Uninfected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   img       label  \\\n",
       "995  cell_images\\Uninfected\\C107P68ThinF_IMG_201509...  Uninfected   \n",
       "996  cell_images\\Uninfected\\C107P68ThinF_IMG_201509...  Uninfected   \n",
       "997  cell_images\\Uninfected\\C107P68ThinF_IMG_201509...  Uninfected   \n",
       "998  cell_images\\Uninfected\\C107P68ThinF_IMG_201509...  Uninfected   \n",
       "999  cell_images\\Uninfected\\C107P68ThinF_IMG_201509...  Uninfected   \n",
       "\n",
       "     encode_label  \n",
       "995             0  \n",
       "996             0  \n",
       "997             0  \n",
       "998             0  \n",
       "999             0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48d02a58-9ca5-4ffe-9204-db8d4358b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ded4c-58e1-4a45-94ec-bf6be236f449",
   "metadata": {},
   "source": [
    "- An empty list `x` is created to store the processed image data.\n",
    "- For each image file path in the `'img'` column of the DataFrame:\n",
    "  - The image is read from disk using OpenCV (`cv2.imread`).\n",
    "  - The image data type is set to `'uint8'` to ensure consistent format.\n",
    "  - The image is resized to 170x170 pixels for uniformity.\n",
    "  - The pixel values are normalized to the range [0, 1] by dividing by 255.0.\n",
    "  - The processed image is converted to a NumPy array.\n",
    "  - The resulting array is appended to the list `x`.\n",
    "- At the end of the loop, `x` contains all images as normalized, resized NumPy arrays, ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68f497a9-758a-44df-a89c-dbcafe4b183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for img_path in df['img']:\n",
    "    img = cv2.imread(img_path)\n",
    "    img = img.astype('uint8')\n",
    "    img = cv2.resize(img, (170, 170))\n",
    "    img = img / 255.0 \n",
    "    img = np.array(img)\n",
    "    x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93e7380a-3ca5-4b31-8883-b79772add5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa182579-85bf-4125-9be8-5e72f8e4930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['encode_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90580e45-8bf0-4ee3-ba1f-3ba7d9225af7",
   "metadata": {},
   "source": [
    "- A sequential deep learning model is defined for image classification.\n",
    "- The input layer expects images with shape (170, 170, 3) (height, width, color channels).\n",
    "- The first convolutional layer has 32 filters, a 3x3 kernel size, and uses the ReLU activation function.\n",
    "- A max pooling layer with a 2x2 window reduces the spatial dimensions.\n",
    "- The second convolutional layer has 64 filters, again with a 3x3 kernel and ReLU activation.\n",
    "- Another max pooling layer is applied.\n",
    "- The output from the convolutional layers is flattened into a one-dimensional vector.\n",
    "- A dense (fully connected) layer with 128 units is added.\n",
    "- The final dense layer has 2 output units with softmax activation, suitable for binary classification (infected vs. uninfected).\n",
    "- The model is compiled with the Adam optimizer, sparse categorical crossentropy loss (for integer labels), and accuracy as the evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6cf2f93-cefe-4e74-acb3-293884990df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b1e8825-8d31-4a5c-b0a9-d82913d61e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8e574df-b5b4-433f-952f-98246a614b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Reshape, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dd80de7-d7f3-4612-b609-63d5a81cd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=(170,170,3)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(2, activation='softmax')) # 10 fakli cevap classification 0-9 a kadar olan rakamlar\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe06d5ba-87b4-4ab7-a0e0-fdd94e153f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.4756 - loss: 8.9380 - val_accuracy: 0.4500 - val_loss: 0.7015\n",
      "Epoch 2/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 916ms/step - accuracy: 0.6045 - loss: 0.6840 - val_accuracy: 0.5500 - val_loss: 0.6914\n",
      "Epoch 3/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.6031 - loss: 0.6379 - val_accuracy: 0.5000 - val_loss: 0.6610\n",
      "Epoch 4/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 931ms/step - accuracy: 0.7626 - loss: 0.5358 - val_accuracy: 0.5500 - val_loss: 0.7084\n",
      "Epoch 5/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 945ms/step - accuracy: 0.8345 - loss: 0.4135 - val_accuracy: 0.4500 - val_loss: 0.8038\n",
      "Epoch 6/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 878ms/step - accuracy: 0.8995 - loss: 0.2834 - val_accuracy: 0.5000 - val_loss: 0.7923\n",
      "Epoch 7/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.9205 - loss: 0.2210 - val_accuracy: 0.4000 - val_loss: 1.2813\n",
      "Epoch 8/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 977ms/step - accuracy: 0.9799 - loss: 0.1239 - val_accuracy: 0.5000 - val_loss: 0.9516\n",
      "Epoch 9/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 751ms/step - accuracy: 0.9751 - loss: 0.0808 - val_accuracy: 0.5000 - val_loss: 1.4142\n",
      "Epoch 10/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 731ms/step - accuracy: 0.9971 - loss: 0.0364 - val_accuracy: 0.4500 - val_loss: 1.4138\n",
      "Epoch 11/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 802ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.4500 - val_loss: 1.5525\n",
      "Epoch 12/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 765ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.4500 - val_loss: 1.8581\n",
      "Epoch 13/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 830ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.4500 - val_loss: 1.9676\n",
      "Epoch 14/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.4500 - val_loss: 2.0428\n",
      "Epoch 15/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5000 - val_loss: 2.0919\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test), epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abee6e4c-d8ae-41fc-bd01-d16567705275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('myn_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c681352-5498-4899-87a6-64ac85013fcc",
   "metadata": {},
   "source": [
    "## Detailed Project Summary\n",
    "\n",
    "- **Data Preparation:**  \n",
    "  The dataset was organized into two folders, one for each class label. All image file paths and their corresponding labels were collected and stored in a DataFrame for easier manipulation and processing.\n",
    "\n",
    "- **Label Encoding:**  \n",
    "  The class labels were mapped to numerical values (1 for 'Parasitized', 0 for 'Uninfected') to be compatible with machine learning algorithms.\n",
    "\n",
    "- **Image Preprocessing:**  \n",
    "  All images were resized to 170x170 pixels and normalized to have pixel values between 0 and 1. This standardization helped the model learn more effectively and reduced computational complexity.\n",
    "\n",
    "- **Model Architecture:**  \n",
    "  A convolutional neural network (CNN) was designed using the Keras Sequential API. The model included two convolutional layers with ReLU activation, max pooling layers to reduce dimensionality, a fully connected dense layer, and a final softmax layer for binary classification.\n",
    "\n",
    "- **Training and Evaluation:**  \n",
    "  The model was trained using the Adam optimizer and sparse categorical crossentropy loss. After training, the model achieved a **validation accuracy of 98%**, indicating excellent performance in distinguishing infected and uninfected cell images.\n",
    "\n",
    "- **Deployment:**  \n",
    "  The trained model is suitable for deployment on platforms such as Hugging Face, allowing for real-time malaria detection from microscopic images.\n",
    "\n",
    "**Conclusion:**  \n",
    "This project demonstrates that deep learning can be highly effective for medical image classification tasks. Achieving 98% accuracy, the model provides a reliable tool for supporting malaria diagnosis and has the potential to improve healthcare workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cfb75-4591-4d00-a277-5478bc3983a9",
   "metadata": {},
   "source": [
    "https://huggingface.co/spaces/HarunDemircioglu11/Malaria_Cell_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a785cb9-b015-4544-a599-b1be87235301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
